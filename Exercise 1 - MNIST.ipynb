{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning workshop - Exercise 1\n",
    "\n",
    "This exercise will take you through training of a deep neural network using Keras. \n",
    "\n",
    "We will train a network to classify handwritten digits using the MNIST dataset.\n",
    "\n",
    "We will cover the following topis: \n",
    "* Loading the data\n",
    "* Building a simpel Keras model\n",
    "* Training a basic network\n",
    "* Evaluation of the model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of Jupyter Notebooks\n",
    "\n",
    "Cell types:\n",
    "* Markdown cells: Cells like this one with markdown-text in it\n",
    "     - Change highlighted cell to markdown with: `m`\n",
    "* Code cells: Python code cells.\n",
    "    - Change highlighted cell to code with: `y`\n",
    "\n",
    "When highlighting cell:\n",
    "* `shift + enter`: Run cell\n",
    "* `enter`: Enter edit mode in cell\n",
    "* `esc`: Exit edit mode in cell\n",
    "\n",
    "From header above:\n",
    "* `Kernel > Interrupt`: Stop long running cell ( you might need this if running too many epochs ).\n",
    "* `Kernel > Restart`: Restart entire notebook, if it really messes up do this and re-run relevant cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## These are some helper functions to plot the outputs of our models. Run the cell to save the functions. \n",
    "\n",
    "def plot_training_epochs(history):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.plot(history.epoch, history.history['categorical_accuracy'])\n",
    "    plt.plot(history.epoch, history.history['val_categorical_accuracy'])\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    l = plt.legend(['training accuracy', 'validation accuracy'])\n",
    "\n",
    "def plot_images_with_label(images, labels, class_):\n",
    "    img_to_plot = images[labels[:, class_]==1, ...]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(15, 10))\n",
    "    for ax, img in zip(axes, img_to_plot):\n",
    "        ax.imshow(array_to_img(img))\n",
    "        ax.axis('off')\n",
    "\n",
    "def print_confusion_matrix(y_true, y_hat, classes):\n",
    "    return pd.DataFrame(confusion_matrix(y_true, y_hat),\n",
    "                        index=['true_' + cls for cls in classes],\n",
    "                        columns=['pred_' + cls for cls in classes])\n",
    "\n",
    "def rand_by_mask(mask, n=4):\n",
    "    return np.random.choice(np.where(mask)[0], n, replace=False)\n",
    "\n",
    "def rand_by_correct(is_correct, y_true, y_hat, n=4):\n",
    "    return rand_by_mask((y_true == y_hat) == is_correct, n=n)\n",
    "\n",
    "def plot_image_ids(image_ids, generator):\n",
    "    images = generator.x[image_ids]\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(15, 10))\n",
    "    for ax, img in zip(axes, images):\n",
    "        ax.imshow(img[..., 0])\n",
    "        ax.axis('off')\n",
    "\n",
    "def plot_correct_classifications(y_true, y_hat, valid_gen, n=4):\n",
    "    image_ids = rand_by_correct(True, y_true, y_hat, n=n)\n",
    "    print(\"Predictions: %s\" % ' '.join(str(i) for i in y_hat[image_ids]))\n",
    "    plot_image_ids(image_ids, valid_gen)\n",
    "\n",
    "def plot_incorrect_classifications(y_true, y_hat, valid_gen, n=4):\n",
    "    image_ids = rand_by_correct(False, y_true, y_hat, n=n)\n",
    "    print(\"Predictions: %s\" % ' '.join(str(i) for i in y_hat[image_ids]))\n",
    "    plot_image_ids(image_ids, valid_gen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "First thing we need to do is load the data. In the following exercise you will work with the MNIST dataset. MNIST is a database of handwritten digits. The digits have been size-normalised and centered making them easy to work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape the dataset\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "# Convert the labels to one-hot encodings\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some of the things we need from keras\n",
    "from keras.preprocessing.image import ImageDataGenerator          # generator to cycle through images\n",
    "from keras.preprocessing.image import array_to_img                # function to convert arrays back to images \n",
    "from keras.applications.imagenet_utils import preprocess_input    # normalization function for ImageNet\n",
    "from keras.preprocessing.image import load_img                    # function to load image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up some global variables\n",
    "# Batch size is how many images the network looks at at a time\n",
    "batch_size = 64\n",
    "\n",
    "# The image size is what we should scale the images to\n",
    "image_size = (28, 28)\n",
    "\n",
    "# This is the number of classes to classify.\n",
    "#    This is important for what the output of the network should look like.\n",
    "#    In this case we have 10 output classes.\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create data generators\n",
    "# Create a generator that can be used for image preprocessing, like normalisation to the ImageNet using the `preprocess_input`. \n",
    "# This generator can also be used for data augmentation of the images\n",
    "data_generator = ImageDataGenerator()\n",
    "\n",
    "# Create the training and validation generators.\n",
    "# They use the image sizes, batch sizes, and paths to data set above.\n",
    "train_gen = data_generator.flow(x_train, y_train, batch_size=batch_size)\n",
    "\n",
    "valid_gen = data_generator.flow(x_test, y_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "classes = list(map(str, range(1, 11)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generators `train_gen` and `test_gen` will iterate over the training and testing images. \n",
    "\n",
    "Each output will be a tuple of image-tensor and label-vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(train_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images here contains a tensor with shape:\n",
    "\n",
    "`(batch_size, image_height, image_width, image_channels)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Try plotting the first image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of labels is a one-hot encoding of the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The helper function: \n",
    "\n",
    "`plot_images(images, labels, class)`\n",
    "\n",
    "can plot the images from one of the classes (given the labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_images_with_label(images, labels, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Try plotting images from one of the other classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a basic network\n",
    "\n",
    "Using some predefined Keras components you can build your own network. In the following section a simpel network has been defined, including two convolutional layers, two max pooling layers, a flatten layer and a dense layer. \n",
    "\n",
    "The network will have 10 outputs (0 - 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(4, kernel_size=3, activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(8, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "opt = Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a basic network\n",
    "\n",
    "To train a model you can run `model.fit_generator`\n",
    "\n",
    "Every time the model has trained once on the training data it will evaluate it's accuracy on the validation data. The resulting training and validation accuracies are printed.\n",
    "\n",
    "When you are done running this you can plot the accuracies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    train_gen,\n",
    "    validation_data=valid_gen,\n",
    "    epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_training_epochs(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "* Is the model training? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model performance\n",
    "\n",
    "The first thing we want to do, when having trained anetwork is to evaluate the performance. We can see how the network does during training above. The orange line is the validation accuracy after each epoch. \n",
    "\n",
    "But let's try and inscept the resulting predictions. \n",
    "\n",
    "We use a confusion matrix, first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some metrics for evaluating the notebook\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "y_pred = model.predict_generator(valid_gen, verbose=1)\n",
    "y_hat = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(valid_gen.y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: %0.4f' % accuracy_score(y_true, y_hat))\n",
    "print('Confusion matrix:')\n",
    "print_confusion_matrix(y_true, y_hat, classes=list(map(str, range(1, 11))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "* Try to interpret the confusion matrix\n",
    "* Are there any patterns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also plot random examples of correctly and incorrectly classified images using the cells below. \n",
    "\n",
    "As they are randomised you can see more examples by rerunning the cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_incorrect_classifications(y_true, y_hat, valid_gen, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_correct_classifications(y_true, y_hat, valid_gen, n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "* What is the model performance?\n",
    "* How can you increase the performance?\n",
    "* Try increasing the number of epochs - can you improve the model results?\n",
    "* Try changing other parameters to obtain the best model performance\n",
    "* Report the highest performance and the method used to get this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback:\n",
    "\n",
    "Please leave any feedback you migh have in the following text cell - then we'll try to improve our workshop for next time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
